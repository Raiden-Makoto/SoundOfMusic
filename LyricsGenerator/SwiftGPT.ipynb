{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T01:56:32.508419Z",
     "iopub.status.busy": "2025-09-22T01:56:32.508203Z",
     "iopub.status.idle": "2025-09-22T01:56:58.621087Z",
     "shell.execute_reply": "2025-09-22T01:56:58.620308Z",
     "shell.execute_reply.started": "2025-09-22T01:56:32.508393Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxcui/miniforge3/envs/mididdsp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./model_checkpoint\"\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(checkpoint_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50259, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "          (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "          (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50259, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiftgpt = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startofsong|> We were both young, naive and wild when we first met, but now we're grown up together (Yeah)\n",
      "‚ÄÖI was the one who broke your heart in a moment of weakness (\"Ooh-ayy\")\n",
      "\n",
      "  ôCause you never trusted me with anything? Well, I'm not so sure about that anymore(Ah), oh, woah, ah (Oh my God)(No way!) …êYou gave it all to him (It's gone) Now he takes what is mine for granted(\"Haha)\" ÀüBut still, this love ain't easy to get back at or even come close ta, ooh-(Aww)-oowwoah, woosh, ah-, uh-huh, ha-haa-heh-ho (Hey), hey ya know where they are right here on my front porch, baby (Come home) Hey, oh, yeah (Baby) You can be anywhere else, babe (Stay away from us forever ) It won' t happen again (Forever & always,) Oh-my goodness, noooooooooooooooeee-ah (Woah-) \"We Were All Young\" by Taylor Swift - Teardrops In My Hair Pt. 2: Let Me Tell The Story Of What Happened To Me And Who Knows Why\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<|startofsong|> We were both young\"\n",
    "outputs = swiftgpt(\n",
    "    prompt,\n",
    "    max_length=400,        # adjust as needed\n",
    "    do_sample=True,        # enables randomness\n",
    "    top_k=50,              # sample from top 50 tokens\n",
    "    top_p=0.65,            # nucleus sampling\n",
    "    temperature=0.9,       # creativity\n",
    "    num_return_sequences=1, # generate 1 song\n",
    "    repetition_penalty=1.5,   # üëà discourage loops\n",
    "    no_repeat_ngram_size=3,   # üëà block repeating n-grams\n",
    ")\n",
    "\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8268421,
     "sourceId": 13057095,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 263246622,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mididdsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
