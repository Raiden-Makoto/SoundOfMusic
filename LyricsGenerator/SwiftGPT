{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13057095,"sourceType":"datasetVersion","datasetId":8268421},{"sourceId":263246622,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T02:54:08.384275Z","iopub.execute_input":"2025-09-23T02:54:08.385174Z","iopub.status.idle":"2025-09-23T02:54:08.390209Z","shell.execute_reply.started":"2025-09-23T02:54:08.385126Z","shell.execute_reply":"2025-09-23T02:54:08.389434Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T02:54:08.683009Z","iopub.execute_input":"2025-09-23T02:54:08.683346Z","iopub.status.idle":"2025-09-23T02:54:08.913964Z","shell.execute_reply.started":"2025-09-23T02:54:08.683321Z","shell.execute_reply":"2025-09-23T02:54:08.912993Z"}},"outputs":[{"name":"stdout","text":"Tue Sep 23 02:54:08 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   41C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  # activate both GPUs\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T02:54:09.366076Z","iopub.execute_input":"2025-09-23T02:54:09.366851Z","iopub.status.idle":"2025-09-23T02:54:09.372291Z","shell.execute_reply.started":"2025-09-23T02:54:09.366808Z","shell.execute_reply":"2025-09-23T02:54:09.371451Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    Trainer,\n    TrainingArguments,\n    TextDataset,\n    DataCollatorForLanguageModeling\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T02:54:12.522746Z","iopub.execute_input":"2025-09-23T02:54:12.523063Z","iopub.status.idle":"2025-09-23T02:54:42.060970Z","shell.execute_reply.started":"2025-09-23T02:54:12.523033Z","shell.execute_reply":"2025-09-23T02:54:42.060151Z"}},"outputs":[{"name":"stderr","text":"2025-09-23 02:54:27.117210: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758596067.335914      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758596067.396949      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2TokenizerFast, pipeline\nimport torch\n\n# path to your trained model folder\ncheckpoint_path = \"/kaggle/input/swiftgpt/taylor_swift_gpt2\"\n\n# load tokenizer + model\ntokenizer = GPT2TokenizerFast.from_pretrained(checkpoint_path)\nmodel = GPT2LMHeadModel.from_pretrained(checkpoint_path)\n\n# pick device (GPU if available)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n\nswiftgpt = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n\nprompt = \"<|startofsong|> We were both young\"\noutputs = swiftgpt(\n    prompt,\n    max_length=400,        # adjust as needed\n    do_sample=True,        # enables randomness\n    top_k=50,              # sample from top 50 tokens\n    top_p=0.65,            # nucleus sampling\n    temperature=0.9,       # creativity\n    num_return_sequences=1, # generate 1 song\n    repetition_penalty=1.5,   # 👈 discourage loops\n    no_repeat_ngram_size=3,   # 👈 block repeating n-grams\n)\n\nprint(outputs[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T03:09:31.744664Z","iopub.execute_input":"2025-09-23T03:09:31.744966Z","iopub.status.idle":"2025-09-23T03:09:41.930119Z","shell.execute_reply.started":"2025-09-23T03:09:31.744935Z","shell.execute_reply":"2025-09-23T03:09:41.929242Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nBoth `max_new_tokens` (=256) and `max_length`(=400) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"<|startofsong|> We were both young and reckless, I was the one who took his hand (Ooh) And we went wild on our way home (Wild), but you could tell by my eyes that this is gonna be a long night(Wild)'Cause it's like your soul can't leave me alone (Oh-hah!) So yeah...we're all in love (We are indeed). Oh oh, woah (Woahs) Woosh-woofers! That'll make us whole (Yeah) You got to come with her (Come along with HER)(Uh huh)-ooh) Hey hey holey girl\n  You know what they say about men of good faith? They've lost their minds over things past (Past), so let 'em down now for once (Let them go back to where THEY came from -ahem-) Let'er runnin', \"Good faith\" gone mad as hell, ahahahaha (Ah ha) Good luck finding someone else right away (Now there's only one left) But she has no time or heart if she wants me dead (She doesn’t want ME DEAD) She said yes when he asked how old we should get together (He wanted ya) Well guess which day turned out better than yesterday? Yesterday turns\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/starspray/taylor_swift_lyrics.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:56:58.623143Z","iopub.execute_input":"2025-09-22T01:56:58.623636Z","iopub.status.idle":"2025-09-22T01:56:58.672076Z","shell.execute_reply.started":"2025-09-22T01:56:58.623616Z","shell.execute_reply":"2025-09-22T01:56:58.671293Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                          Song  \\\n0  \"Slut!\" (Taylor's Version) (From The Vault)   \n1                        22 (Taylor's Version)   \n2                       A Perfectly Good Heart   \n3                        A Place in this World   \n4                                    Afterglow   \n\n                                              Lyrics  \n0  [Verse 1]\\nFlamingo pink, Sunrise Boulevard\\nC...  \n1  [Verse 1]\\nIt feels like a perfect night\\nTo d...  \n2  [Chorus]\\nWhy would you wanna break\\nA perfect...  \n3  [Verse 1]\\nI don't know what I want, so don't ...  \n4  [Verse 1]\\nI blew things out of proportion, no...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Song</th>\n      <th>Lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"Slut!\" (Taylor's Version) (From The Vault)</td>\n      <td>[Verse 1]\\nFlamingo pink, Sunrise Boulevard\\nC...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22 (Taylor's Version)</td>\n      <td>[Verse 1]\\nIt feels like a perfect night\\nTo d...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A Perfectly Good Heart</td>\n      <td>[Chorus]\\nWhy would you wanna break\\nA perfect...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A Place in this World</td>\n      <td>[Verse 1]\\nI don't know what I want, so don't ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Afterglow</td>\n      <td>[Verse 1]\\nI blew things out of proportion, no...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"with open(\"taylor_swift_songs_prepared.txt\", \"w\", encoding=\"utf-8\") as f:\n    for _, row in df.iterrows():\n        f.write(\"<|startofsong|>\\n\")\n        f.write(f\"Song: {row['Song']}\\n\")\n        f.write(f\"{row['Lyrics']}\\n\")\n        f.write(\"<|endofsong|>\\n\\n\")\n\nprint(\"✅ Preprocessing complete! Training text file created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:56:58.672957Z","iopub.execute_input":"2025-09-22T01:56:58.673247Z","iopub.status.idle":"2025-09-22T01:56:58.691716Z","shell.execute_reply.started":"2025-09-22T01:56:58.673222Z","shell.execute_reply":"2025-09-22T01:56:58.691114Z"}},"outputs":[{"name":"stdout","text":"✅ Preprocessing complete! Training text file created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def clean_text(text):\n    if not isinstance(text, str):\n        return \"\"\n    text = text.lower()\n    # Replace structure tags with special tokens\n    replacements = {\n        r\"\\[verse.*?\\]\": \"<verse>\",\n        r\"\\[chorus.*?\\]\": \"<chorus>\",\n        r\"\\[bridge.*?\\]\": \"<bridge>\",\n        r\"\\[outro.*?\\]\": \"<outro>\",\n        r\"\\[intro.*?\\]\": \"<intro>\"\n    }\n    for pat, tok in replacements.items():\n        text = re.sub(pat, tok, text, flags=re.IGNORECASE)\n    # Remove remaining brackets\n    text = re.sub(r\"[\\[\\]]\", \"\", text)\n    # Keep letters, numbers, spaces, angle brackets\n    text = re.sub(r\"[^a-z0-9<>\\s]\", \" \", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:56:58.692372Z","iopub.execute_input":"2025-09-22T01:56:58.692561Z","iopub.status.idle":"2025-09-22T01:56:58.697421Z","shell.execute_reply.started":"2025-09-22T01:56:58.692546Z","shell.execute_reply":"2025-09-22T01:56:58.696627Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model_name = \"gpt2-medium\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:56:58.698112Z","iopub.execute_input":"2025-09-22T01:56:58.698393Z","iopub.status.idle":"2025-09-22T01:56:58.712281Z","shell.execute_reply.started":"2025-09-22T01:56:58.698374Z","shell.execute_reply":"2025-09-22T01:56:58.711707Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:56:58.712888Z","iopub.execute_input":"2025-09-22T01:56:58.713117Z","iopub.status.idle":"2025-09-22T01:57:00.697098Z","shell.execute_reply.started":"2025-09-22T01:56:58.713101Z","shell.execute_reply":"2025-09-22T01:57:00.696486Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3557e159536142b79fb1d54ea932453f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5850f62827fb49e69abe016caac5a40b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"435cf849488d4edf8fd89cf6065d930b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72bb230601eb4e999a498d7466e3fc69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2dfe97075a84ad796089b9a139ebfa5"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"special_tokens = {\"additional_special_tokens\": [\"<|startofsong|>\", \"<|endofsong|>\"]}\ntokenizer.add_special_tokens(special_tokens)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:57:00.697781Z","iopub.execute_input":"2025-09-22T01:57:00.697993Z","iopub.status.idle":"2025-09-22T01:57:00.703416Z","shell.execute_reply.started":"2025-09-22T01:57:00.697976Z","shell.execute_reply":"2025-09-22T01:57:00.702630Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:57:00.704102Z","iopub.execute_input":"2025-09-22T01:57:00.704289Z","iopub.status.idle":"2025-09-22T01:57:08.536125Z","shell.execute_reply.started":"2025-09-22T01:57:00.704275Z","shell.execute_reply":"2025-09-22T01:57:08.535444Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94ba6b45cbc244f88047c4494ce1adb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74f176182cc14320a022a294f4fabf70"}},"metadata":{}},{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Embedding(50259, 1024)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:57:08.536842Z","iopub.execute_input":"2025-09-22T01:57:08.537077Z","iopub.status.idle":"2025-09-22T01:57:08.540545Z","shell.execute_reply.started":"2025-09-22T01:57:08.537060Z","shell.execute_reply":"2025-09-22T01:57:08.539737Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset = load_dataset(\"text\", data_files={\"train\": \"taylor_swift_songs_prepared.txt\"})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:57:08.541259Z","iopub.execute_input":"2025-09-22T01:57:08.541493Z","iopub.status.idle":"2025-09-22T01:57:11.787049Z","shell.execute_reply.started":"2025-09-22T01:57:08.541477Z","shell.execute_reply":"2025-09-22T01:57:11.786363Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99d15ee569d8409cbb5cfc5eab07d162"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"def tokenize_fn(batch):\n    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n\ntokenized_dataset = dataset[\"train\"].map(tokenize_fn, batched=True, remove_columns=[\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:57:11.789202Z","iopub.execute_input":"2025-09-22T01:57:11.789409Z","iopub.status.idle":"2025-09-22T01:57:14.861270Z","shell.execute_reply.started":"2025-09-22T01:57:11.789393Z","shell.execute_reply":"2025-09-22T01:57:14.860463Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12850 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d94b2f8cfcf044b6ae6604a99a6b83b0"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:57:14.862047Z","iopub.execute_input":"2025-09-22T01:57:14.862371Z","iopub.status.idle":"2025-09-22T01:57:14.867332Z","shell.execute_reply.started":"2025-09-22T01:57:14.862335Z","shell.execute_reply":"2025-09-22T01:57:14.866460Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./taylor_swift_gpt2\",   # save everything here\n    overwrite_output_dir=True,\n    num_train_epochs=1,                   # tune higher for better results\n    per_device_train_batch_size=2,        # safe for Kaggle T4\n    gradient_accumulation_steps=8,   # simulate batch size 8\n    save_strategy=\"epoch\",                # save every epoch\n    save_total_limit=2,                   # keep last 2 checkpoints\n    logging_dir=\"./logs\",\n    logging_strategy=\"steps\",\n    logging_steps=1000,                     # log every 50 steps\n    prediction_loss_only=True,            # cleaner logs\n    report_to=\"none\",                     # disable wandb/tensorboard\n    fp16=True,                            # use mixed precision if available\n    disable_tqdm=False                    # progress bar\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:57:14.868203Z","iopub.execute_input":"2025-09-22T01:57:14.868476Z","iopub.status.idle":"2025-09-22T01:57:21.243082Z","shell.execute_reply.started":"2025-09-22T01:57:14.868454Z","shell.execute_reply":"2025-09-22T01:57:21.242067Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=tokenized_dataset\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:57:21.244002Z","iopub.execute_input":"2025-09-22T01:57:21.244267Z","iopub.status.idle":"2025-09-22T01:57:22.688427Z","shell.execute_reply.started":"2025-09-22T01:57:21.244244Z","shell.execute_reply":"2025-09-22T01:57:22.687843Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(\"./taylor_swift_gpt2\")\ntokenizer.save_pretrained(\"./taylor_swift_gpt2\")\n\nprint(\"✅ Fine-tuning complete! Model saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T01:57:22.689157Z","iopub.execute_input":"2025-09-22T01:57:22.689403Z","iopub.status.idle":"2025-09-22T02:44:10.495444Z","shell.execute_reply.started":"2025-09-22T01:57:22.689376Z","shell.execute_reply":"2025-09-22T02:44:10.494630Z"}},"outputs":[{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='402' max='402' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [402/402 46:36, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"✅ Fine-tuning complete! Model saved.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from transformers import pipeline, GPT2LMHeadModel, GPT2TokenizerFast","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T02:56:35.348765Z","iopub.execute_input":"2025-09-22T02:56:35.349519Z","iopub.status.idle":"2025-09-22T02:56:35.353109Z","shell.execute_reply.started":"2025-09-22T02:56:35.349489Z","shell.execute_reply":"2025-09-22T02:56:35.352271Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained(\"./taylor_swift_gpt2\")\ntokenizer = GPT2TokenizerFast.from_pretrained(\"./taylor_swift_gpt2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T02:56:44.358919Z","iopub.execute_input":"2025-09-22T02:56:44.359662Z","iopub.status.idle":"2025-09-22T02:56:44.675177Z","shell.execute_reply.started":"2025-09-22T02:56:44.359638Z","shell.execute_reply":"2025-09-22T02:56:44.674409Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"swiftgpt = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T02:56:47.223288Z","iopub.execute_input":"2025-09-22T02:56:47.224016Z","iopub.status.idle":"2025-09-22T02:56:47.692833Z","shell.execute_reply.started":"2025-09-22T02:56:47.223990Z","shell.execute_reply":"2025-09-22T02:56:47.692087Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"prompt = \"<|startofsong|> It feels like a\"\noutputs = swiftgpt(\n    prompt,\n    max_length=400,        # adjust as needed\n    do_sample=True,        # enables randomness\n    top_k=50,              # sample from top 50 tokens\n    top_p=0.65,            # nucleus sampling\n    temperature=0.9,       # creativity\n    num_return_sequences=1, # generate 1 song\n    repetition_penalty=1.5,   # 👈 discourage loops\n    no_repeat_ngram_size=3,   # 👈 block repeating n-grams\n)\n\nprint(outputs[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T02:57:13.685052Z","iopub.execute_input":"2025-09-22T02:57:13.685314Z","iopub.status.idle":"2025-09-22T02:57:21.999898Z","shell.execute_reply.started":"2025-09-22T02:57:13.685295Z","shell.execute_reply":"2025-09-22T02:57:21.999150Z"}},"outputs":[{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=400) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"<|startofsong|> It feels like a million dollars is at stake (Oh-oh) And it's so hard to lose your temper when you're with me, baby\n ʙCause I can't help myself (Baby), oh my god(Awwwww!) Oh yes and no one knows what I'm doin' right now(Noone cares about him, but he does care )(Ooh woah) OOH oohwoah woayyeeeow(Haha hahahah)(Hey) Hey hey ho, yeah, hi (Hello)/He never knew that we were friends until this morning/Yeah—yeah–yeah (Yes) You are the reason why I don know how much time has passed since last night /I have been thinking of you eversince our first kiss /And yet there was nobody who said anything or looked up from their phone screens while I stood in front on the porch looking down into the street outside where all these other girls had just gone crazy & started singing \"Never Ever Say Goodbye\" over their hearts. The whole town went wild So they put signs out across the streets saying: \"Love Is Blind\" —But then someone got mad at them for not seeing through the haze? So instead … guess she'll say goodbye\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/taylor_swift_gpt2\")\ntokenizer.save_pretrained(\"/kaggle/working/taylor_swift_gpt2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T02:59:06.703728Z","iopub.execute_input":"2025-09-22T02:59:06.704505Z","iopub.status.idle":"2025-09-22T02:59:11.190289Z","shell.execute_reply.started":"2025-09-22T02:59:06.704473Z","shell.execute_reply":"2025-09-22T02:59:11.189417Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/taylor_swift_gpt2/tokenizer_config.json',\n '/kaggle/working/taylor_swift_gpt2/special_tokens_map.json',\n '/kaggle/working/taylor_swift_gpt2/vocab.json',\n '/kaggle/working/taylor_swift_gpt2/merges.txt',\n '/kaggle/working/taylor_swift_gpt2/added_tokens.json',\n '/kaggle/working/taylor_swift_gpt2/tokenizer.json')"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}